=======================
### Resolutions

Different resolutions can be asked for.

For a 16U image,
Threshold computation is always the same if using 32F.
With 16U, calculation of threshold loose precision and we might have small differences if numbers are rounded up or down.
=> Done, but no clear gain?


========================
### Determining Threshold

percentile might be derived from the histogram (so less data need to be stored)
but we then we sort all the pixels to figure out the pixel intensity at which we can cut off, that is extremely inefficient
since we need to sort billions of pixels in ascending order, and stored the result.

=> using an higher level of pyramid is not working since intensity is averaged. It is complicated to figure out exactly the loss.
=> a sampling approach on a small subset of data seems to work well.

DONE

====================
Current Improvements

Threshold finder
    Sampling should gives good results and cut memory consumption even by keeping the current technique

Blobs are now compacted into Feature before being sent to merge.
    It cuts down on memory consumption by a factor of 64. (2 32bits coord vs 1bit per pixel)



===================
Usage

Previous : Online : 60s anf 6GB for a 800MB image

The phase of discovery where we find the right parameters can be done at an higher pyramid level.
For our test data a 800MB image, which takes 27s at level 0, takes 7 sec at level 1 and 2s at level 2.
So running at level 2 gives us essentially an online algo (takes 300MB of memory).
Once parameters are found, segmentation can be run at level 0 again -> (27s / 600MB).


===================
TODO

Improvement : accelerate.
 In merge, we should look at each pixel in the list of coordinates and if it is in the blob we just merged, we should delete them.

Parameterize erosion with different erosion


Connectivity 8 for analyser
-------------------

EROSION ON FEATURE TILE RATHER THAN FULL FEATURES
Two approach :
- read from disk, rewrite each as a mask, apply erosion, write bitmask back => a lot of extra computation + IO
- have a loader of feature bitmask in fast image. Unpack tile, erode, copy back the modified bitmask
(but not necessarily a tight bounding box anymore).

Better : rewrite custom erosion on feature.
Any other treatment that would require only the bitmask? Probably not. Only feature extraction that has to do with shape.



=====================
How this work transform the original workflow?

We have to review the workflow if we want to be efficient.
Example : in the original code we do an erosion step before generating the mask.
We cannot do that anymore : we generate feature early on that we merge. They describe the number of pixels for each feature.
If we do erosion, we need to:
 - 1/ generate the mask data from the feature
 - 2/generate apply erosion
 - 3/write the mask
 - 4/regenerate the feature collection if we need them (so the values can be updated).


Optimization problem
We could discard the holes beyond a certain size, deeming there are background for sure.
This could prevent keeping around a lot background pixels.
However, on the flip side, note that this implies that later in the merge stage
we will potentially try to merge contiguous "holes" to this missing background.
Then those holes could be seen as too small and removed, creating bridges between two blobs when it should not.
And since we do not expect this bad result, we could generate a labeled mask
with what seem one object but labeled as several objects.


==================
Things to look at

For dataset test2, two background blobs are found not be linked even though it look like they are connected in the final mask


=================
DOMAIN : THINGS TO ASK

can we take a percentile in the histogram rather than in the full pixel info?
That would be huge perf improvment.


================================
Optimizations

Resolution
- Resolution adapts to the input. We won't manipulate 32bits floating point encoded gradient if the input image is 8bits.
- We adapt the labeled mask resolution to the number of features represented. Ex: if we have 120 features, we will only generate an 8bit mask.

Thresholdfinder
 - limit the number of operations, duplication of data structures etc....
 - sampling the image to calculate the histogram and the gradient pixel threshold intensity.
 - possibility to use a higher resolution if using a pyramid (does not seem to lead to valid result)

Intensity Threshold values :
 - Bounds can also be computed at a higher level of the pyramid.

Local treatment for mask generation with a merging step.



